{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Starting out with time series analysis and labeling tasks. \n",
    "    A common scenario is when you have data for every minute, but you only need \n",
    "    hourly data. Or vice versa. Or you have data at different time intervals and\n",
    "    you would like to make a regular time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2011-01-01 00:00:00    0\n",
       "2011-01-01 01:00:00    1\n",
       "2011-01-01 02:00:00    2\n",
       "2011-01-01 03:00:00    3\n",
       "2011-01-01 04:00:00    4\n",
       "Freq: H, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng_index = pd.date_range(start = '1/1/2011', periods = 72, freq = 'H')\n",
    "df = pd.Series(list(range(len(rng_index))), index = rng_index)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    I would like to think of the above data in terms of every 45 mins and not hours. In the output below \n",
    "    it drops certain data points from the previous df, and includes some data points as well. We choose \n",
    "    to carry forward the values at previous timestamps to newly created timestamps. This is necessary, since\n",
    "    there is no value for these timestamps in the original df. Therefore, eventhough old datapoints could be lost, they\n",
    "    still have influence on newly generated data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2011-01-01 00:00:00    0\n",
       "2011-01-01 00:45:00    0\n",
       "2011-01-01 01:30:00    1\n",
       "2011-01-01 02:15:00    2\n",
       "2011-01-01 03:00:00    3\n",
       "Freq: 45T, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_modified = df.asfreq('45min', method='ffill')\n",
    "df_modified.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Since ffill looked at what came before it to fill in values for new data points, \n",
    "    bfill looks at the data points that come after it to fill in values for new data points.\n",
    "    Domain knowledge could come into play when considering the fill method for new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011-01-01 00:00:00    0.0\n",
      "2011-01-01 00:45:00    NaN\n",
      "2011-01-01 01:30:00    NaN\n",
      "2011-01-01 02:15:00    NaN\n",
      "2011-01-01 03:00:00    3.0\n",
      "Freq: 45T, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#when you'd like to retain info from old timestamps, and let\n",
    "#new timestamps to be as they are, then method=None does the job.\n",
    "df_modified2 = df.asfreq('45min', method=None)\n",
    "print(df_modified2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look into the docs(normalize, fill_value, etc...)\n",
    "df.asfreq??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2011-01-01 00:00:00     0\n",
       "2011-01-01 03:00:00     3\n",
       "2011-01-01 06:00:00     6\n",
       "2011-01-01 09:00:00     9\n",
       "2011-01-01 12:00:00    12\n",
       "Freq: 3H, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_freq = df.asfreq('3H')\n",
    "low_freq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2011-01-01 02:00:00    0.5\n",
       "2011-01-01 04:00:00    2.5\n",
       "2011-01-01 06:00:00    4.5\n",
       "2011-01-01 08:00:00    6.5\n",
       "2011-01-01 10:00:00    8.5\n",
       "Freq: 2H, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we might need summary statistics on the data points that are \n",
    "#dropped from the original dataset. So we use resample, which\n",
    "#is a more flexible version of asfreq. It lets you do fancier \n",
    "#stuff in addition to ffill or bfill\n",
    "type(df.resample('2H', label=\"right\"))\n",
    "df.resample('2H', label=\"right\").mean().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Irregular Time Series and Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    The code below makes use of np.random.choice to generate a random list of 10 numbers\n",
    "    without replacement. We use this list of random numbers to choose the respective rows\n",
    "    from the original df. This would create an irregular timeseries, where we can use\n",
    "    resample to show it's versatility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "irreg_ts = df[list(np.random.choice(a=range(len(rng_index)), size=10, replace=False))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2011-01-02 04:00:00    28\n",
       "2011-01-02 19:00:00    43\n",
       "2011-01-03 20:00:00    68\n",
       "2011-01-01 20:00:00    20\n",
       "2011-01-01 15:00:00    15\n",
       "2011-01-03 14:00:00    62\n",
       "2011-01-02 01:00:00    25\n",
       "2011-01-01 16:00:00    16\n",
       "2011-01-01 03:00:00     3\n",
       "2011-01-03 15:00:00    63\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irreg_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2011-01-02 04:00:00    28.0\n",
       "2011-01-03 04:00:00     NaN\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#resampling from the above dataset to create a timeseries of daily frequency\n",
    "#would not work, since pandas expects order in data in timeseries.\n",
    "irreg_ts.asfreq('D') #the output proves our point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there we bring order to the data by sorting the index col\n",
    "irreg_ts = irreg_ts.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2011-01-01 03:00:00     3\n",
       "2011-01-01 15:00:00    15\n",
       "2011-01-01 16:00:00    16\n",
       "2011-01-01 20:00:00    20\n",
       "2011-01-02 01:00:00    25\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irreg_ts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2011-01-01 03:00:00     3\n",
       "2011-01-02 03:00:00    25\n",
       "2011-01-03 03:00:00    43\n",
       "Freq: D, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irreg_ts.asfreq('D', method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2011-01-01    13.500000\n",
       "2011-01-02    32.000000\n",
       "2011-01-03    64.333333\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irreg_ts.resample('1D').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Difference between asfreq() and resample()?\n",
    "\n",
    "asfreq() helps you to upsample or downsample your time series, filling in new data\n",
    "according to your choice. resample is just like asfreq(), in the sense that you \n",
    "upsample and downsample. It is like a groupby object, and can be used to apply\n",
    "aggregate statistics upon downsampling you timeseries data, unlike asfreq().\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2011-01-01 00:00:00    0.0\n",
       "2011-01-01 00:10:00    0.0\n",
       "2011-01-01 00:20:00    0.0\n",
       "2011-01-01 00:30:00    0.0\n",
       "2011-01-01 00:40:00    NaN\n",
       "2011-01-01 00:50:00    NaN\n",
       "2011-01-01 01:00:00    1.0\n",
       "2011-01-01 01:10:00    1.0\n",
       "2011-01-01 01:20:00    1.0\n",
       "2011-01-01 01:30:00    1.0\n",
       "Freq: 10T, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "How to partially forward fill?\n",
    "\n",
    "Consider the following scenario : I have a regular time series whose freq=6D.\n",
    "I upsample this time series to freq=1D, and I know that the value for new timestamps\n",
    "can forward filled upto 2 days only. So the rest would be filled with NaN. So, how\n",
    "can we do this?\n",
    "\"\"\"\n",
    "\n",
    "#asfreq with method=None (which is the default value, shown here explicitly), and then use fillna!\n",
    "df.asfreq('10min', method=None).fillna(method='ffill', limit=3).head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
